import requests
import os
import xml.etree.ElementTree as ET
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.documents import Document
# --- ì„¤ì • ---
load_dotenv()
MOLEG_API_KEY = os.getenv("MOLEG_API_KEY")
EMBEDDING_MODEL = "jhgan/ko-sbert-nli" # í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸

def search_law_id(law_name):
    """
    ë²•ë ¹ ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ 'ë²•ë ¹ID'ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. (ì˜ˆ: 001747 -> 1747)
    """
    SEARCH_URL = f"http://www.law.go.kr/DRF/lawSearch.do?OC={MOLEG_API_KEY}&target=eflaw&query={law_name}&type=xml"
    print(SEARCH_URL)
    try:
        response = requests.get(SEARCH_URL, timeout=5)
        if response.status_code == 200:
            try:
                root = ET.fromstring(response.content)
            except ET.ParseError:
                return None, None
            
            laws = root.findall("law")
            if not laws:
                return None, None

            target_law = None
            query_clean = law_name.replace(" ", "").strip()
            
            # 1ë‹¨ê³„: ì™„ì „ ì¼ì¹˜
            for law in laws:
                name_node = law.find("ë²•ë ¹ëª…í•œê¸€")
                if name_node is not None and name_node.text:
                    if name_node.text.replace(" ", "").strip() == query_clean:
                        target_law = law
                        break
            
            # 2ë‹¨ê³„: ë¶€ë¶„ ì¼ì¹˜ (ê°€ì¥ ì§§ì€ ì´ë¦„)
            if not target_law:
                candidates = []
                for law in laws:
                    name_node = law.find("ë²•ë ¹ëª…í•œê¸€")
                    if name_node is not None and name_node.text and query_clean in name_node.text.replace(" ", ""):
                        candidates.append(law)
                if candidates:
                    candidates.sort(key=lambda x: len(x.find("ë²•ë ¹ëª…í•œê¸€").text))
                    target_law = candidates[0]

            if not target_law:
                target_law = laws[0]

            raw_id = target_law.find("ë²•ë ¹ID").text
            law_name_res = target_law.find("ë²•ë ¹ëª…í•œê¸€").text
            
            # ID í¬ë§·íŒ… (ì•ì˜ 0 ì œê±°)
            if raw_id.isdigit():
                processed_id = str(int(raw_id))
            else:
                processed_id = raw_id
            
            print(f"DEBUG: ë²•ë ¹ ID ì¶”ì¶œ - {law_name_res} ({processed_id})")
            return processed_id, law_name_res
            
    except Exception as e:
        print(f"ë²•ë ¹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
    
    return None, None

def get_law_content_xml(law_id):
    """ë²•ë ¹IDë¡œ XML ë³¸ë¬¸ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
    DETAIL_URL = f"http://www.law.go.kr/DRF/lawService.do?OC={MOLEG_API_KEY}&target=eflaw&ID={law_id}&type=xml"
    print(DETAIL_URL)

    try:
        response = requests.get(DETAIL_URL, timeout=10)
        if response.status_code == 200:
            return response.content
    except Exception as e:
        print(f"ë²•ë ¹ ë³¸ë¬¸ ì¡°íšŒ ì˜¤ë¥˜: {e}")
    return None

def parse_articles_from_xml(xml_content):
    """
    [Robust Parsing]
    êµ¬ì¡°ë¥¼ ì—„ê²©í•˜ê²Œ ë”°ì§€ëŠ” ëŒ€ì‹ , 'ì¡°ë¬¸ë‹¨ìœ„' ë‚´ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ìˆœì„œëŒ€ë¡œ ê¸ì–´ì˜µë‹ˆë‹¤.
    íƒœê·¸ ì´ë¦„ì„ ë³´ê³  ì ì ˆí•œ ë“¤ì—¬ì“°ê¸°ë§Œ ì¶”ê°€í•©ë‹ˆë‹¤.
    """
    if not xml_content: return []

    try:
        root = ET.fromstring(xml_content)
        articles_text_list = []

        # <ì¡°ë¬¸> ì„¹ì…˜ ì°¾ê¸°
        jomon_section = root.find("ì¡°ë¬¸")
        if jomon_section is None:
            return []
        
        # ê° <ì¡°ë¬¸ë‹¨ìœ„> ìˆœíšŒ
        for unit in jomon_section.findall("ì¡°ë¬¸ë‹¨ìœ„"):
            # ì¡°ë¬¸ì—¬ë¶€ê°€ 'ì¡°ë¬¸'ì¸ ê²ƒë§Œ ì²˜ë¦¬ (ë¶€ì¹™ ë“± ì œì™¸)
            type_node = unit.find("ì¡°ë¬¸ì—¬ë¶€")
            if type_node is not None and type_node.text != "ì¡°ë¬¸":
                continue

            text_buffer = []
            
            # â­ï¸ í•µì‹¬: .iter()ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¹Šì´ì— ìƒê´€ì—†ì´ ëª¨ë“  í•˜ìœ„ íƒœê·¸ë¥¼ ìˆœì„œëŒ€ë¡œ ë°©ë¬¸
            for elem in unit.iter():
                # í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ìŠ¤í‚µ
                if not elem.text or not elem.text.strip():
                    continue
                
                tag = elem.tag
                text = elem.text.strip()
                
                # íƒœê·¸ì— ë”°ë¥¸ í¬ë§·íŒ… (ë“¤ì—¬ì“°ê¸° ë° ì¤„ë°”ê¿ˆ)
                if tag == "ì¡°ë¬¸ë‚´ìš©":
                    # ì¡°ë¬¸ ì œëª©ì€ ë§¨ ì•ì— (ì¤„ë°”ê¿ˆ ì—†ìŒ)
                    text_buffer.append(text)
                
                elif tag == "í•­ë²ˆí˜¸":
                    # í•­ ë²ˆí˜¸ (â‘ ) : ì¤„ë°”ê¿ˆ í›„ ë“¤ì—¬ì“°ê¸° 2ì¹¸
                    text_buffer.append(f"\n  {text}")
                elif tag == "í•­ë‚´ìš©":
                    # í•­ ë‚´ìš© : ë²ˆí˜¸ ë’¤ì— ë¶™ì„ (ê³µë°± 1ì¹¸)
                    text_buffer.append(f" {text}")
                
                elif tag == "í˜¸ë²ˆí˜¸":
                    # í˜¸ ë²ˆí˜¸ (1.) : ì¤„ë°”ê¿ˆ í›„ ë“¤ì—¬ì“°ê¸° 4ì¹¸
                    text_buffer.append(f"\n    {text}")
                elif tag == "í˜¸ë‚´ìš©":
                    text_buffer.append(f" {text}")
                
                elif tag == "ëª©ë²ˆí˜¸":
                    # ëª© ë²ˆí˜¸ (ê°€.) : ì¤„ë°”ê¿ˆ í›„ ë“¤ì—¬ì“°ê¸° 6ì¹¸
                    text_buffer.append(f"\n      {text}")
                elif tag == "ëª©ë‚´ìš©":
                    text_buffer.append(f" {text}")
            
            # ë²„í¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°
            full_article = "".join(text_buffer).strip()
            
            if full_article:
                articles_text_list.append(full_article)

        print(f"DEBUG: ì´ {len(articles_text_list)}ê°œì˜ ì¡°ë¬¸ì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        return articles_text_list[:100] # ìƒìœ„ 100ê°œ

    except Exception as e:
        print(f"XML íŒŒì‹± ì˜¤ë¥˜: {e}")
        return []

# ğŸ†• --- ì‹¤ì‹œê°„ ë²¡í„° ê²€ìƒ‰ í•¨ìˆ˜ ---
def search_law_articles_semantically(law_name, user_question, k=2):
    """
    1. APIë¡œ ë²•ë ¹ ì „ë¬¸ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    2. ë©”ëª¨ë¦¬ì— ì„ì‹œ Vector DBë¥¼ ë§Œë“­ë‹ˆë‹¤.
    3. ì‚¬ìš©ì ì§ˆë¬¸ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ ì¡°í•­ kê°œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    # 1. ë²•ë ¹ ê²€ìƒ‰ ë° ë³¸ë¬¸ íŒŒì‹±
    law_id, real_name = search_law_id(law_name)
    if not law_id:
        return None, []
    
    xml_content = get_law_content_xml(law_id)
    articles = parse_articles_from_xml(xml_content)
    
    if not articles:
        return real_name, []

    print(f"DEBUG: '{real_name}' ì¡°í•­ {len(articles)}ê°œ ì‹¤ì‹œê°„ ë²¡í„°í™” ì‹œì‘...")

    # 2. ì‹¤ì‹œê°„ ë²¡í„° DB ìƒì„± (In-Memory)
    try:
        embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
        # ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¥¼ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        docs = [Document(page_content=art, metadata={"source": real_name}) for art in articles]
        
        # FAISS ì¸ë±ìŠ¤ ìƒì„± (ë§¤ìš° ë¹ ë¦„)
        vectorstore = FAISS.from_documents(docs, embeddings)
        
        # 3. ì˜ë¯¸ ê²€ìƒ‰ ìˆ˜í–‰
        results = vectorstore.similarity_search(user_question, k=k)
        
        # ê²°ê³¼ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        final_articles = [doc.page_content for doc in results]
        print(f"DEBUG: ë²¡í„° ê²€ìƒ‰ ì™„ë£Œ. ìƒìœ„ {k}ê°œ ì¡°í•­ ì¶”ì¶œ.")
        
        return real_name, final_articles

    except Exception as e:
        print(f"âŒ ë²¡í„°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ ì‹œ ê·¸ëƒ¥ ì•ë¶€ë¶„ ë°˜í™˜
        return real_name, articles[:k]

# ==========================================
# ğŸ§ª í…ŒìŠ¤íŠ¸ ì½”ë“œ
# ==========================================
if __name__ == "__main__":
    print("--- [ì‹¤ì‹œê°„ ë²¡í„° RAG] ë²•ë ¹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ---")
    question = "ìë™ì°¨ íŠœë‹ ìŠ¹ì¸ ì ˆì°¨ê°€ ì–´ë–»ê²Œ ë¼?"
    target_law = "ìë™ì°¨ê´€ë¦¬ë²•"
    
    print(f"ì§ˆë¬¸: {question}")
    print(f"ëŒ€ìƒ ë²•ë ¹: {target_law}")
    
    name, arts = search_law_articles_semantically(target_law, question, k=1)
    
    if name:
        print(f"\nâœ… ê²€ìƒ‰ëœ ë²•ë ¹: {name}")
        if arts:
            print(f"\nâœ… AIê°€ ì„ íƒí•œ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ì¡°í•­:\n{'-'*30}\n{arts[0]}\n{'-'*30}")
        else:
            print("âš ï¸ ì¡°í•­ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    else:
        print("âŒ ë²•ë ¹ ê²€ìƒ‰ ì‹¤íŒ¨")